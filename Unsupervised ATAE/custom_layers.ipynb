{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras import constraints\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Layer(Layer):\n",
    "    def __init__(self,\n",
    "                 W_regularizer=None,\n",
    "                 b_regularizer=None,\n",
    "                 W_constraint=None,\n",
    "                 b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        super(Attention_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert type(input_shape) == list\n",
    "        assert len(input_shape) == 2\n",
    "\n",
    "        self.steps = input_shape[0][1]\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(1,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input_tensor, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        x = input_tensor[0]\n",
    "        y = input_tensor[1]\n",
    "        mask = mask[0]\n",
    "\n",
    "        y = K.transpose(K.dot(self.W, K.transpose(y)))\n",
    "        y = K.expand_dims(y, axis=-2)\n",
    "        y = K.repeat_elements(y, self.steps, axis=1)\n",
    "        eij = K.sum(x * y, axis=-1)\n",
    "\n",
    "        if self.bias:\n",
    "            b = K.repeat_elements(self.b, self.steps, axis=0)\n",
    "            eij += b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        return a\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0], input_shape[0][1]\n",
    "\n",
    "\n",
    "class WeightedSum_Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(WeightedSum_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        assert type(input_tensor) == list\n",
    "        assert type(mask) == list\n",
    "\n",
    "        x = input_tensor[0]\n",
    "        a = input_tensor[1]\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], input_shape[0][-1])\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.get_output_shape_for(input_shape)\n",
    "\n",
    "\n",
    "class WeightedAspectEmb_Layer(Layer):\n",
    "    def __init__(self, input_dim, output_dim,\n",
    "                 init='uniform', input_length=None,\n",
    "                 W_regularizer=None, activity_regularizer=None,\n",
    "                 W_constraint=None,\n",
    "                 weights=None, dropout=0., **kwargs):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.init = initializers.get(init)\n",
    "        self.input_length = input_length\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "\n",
    "        if 0. < self.dropout < 1.:\n",
    "            self.uses_learning_phase = True\n",
    "        self.initial_weights = weights\n",
    "        kwargs['input_shape'] = (self.input_length,)\n",
    "        kwargs['input_dtype'] = K.floatx()\n",
    "        super(WeightedAspectEmb_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=(self.input_dim, self.output_dim),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return K.dot(x, self.W)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.get_output_shape_for(input_shape)\n",
    "\n",
    "\n",
    "class Average_Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        super(Average_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "        return K.sum(x, axis=-2) / K.sum(mask, axis=-2)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape[0:-2] + input_shape[-1:]\n",
    "\n",
    "    def compute_mask(self, x, mask=None):\n",
    "        return None\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.get_output_shape_for(input_shape)\n",
    "\n",
    "\n",
    "class MaxMargin_Layer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaxMargin_Layer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        z_s = input_tensor[0]\n",
    "        z_n = input_tensor[1]\n",
    "        r_s = input_tensor[2]\n",
    "\n",
    "        z_s = K.l2_normalize(z_s, axis=-1)\n",
    "        z_n = K.l2_normalize(z_n, axis=-1)\n",
    "        r_s = K.l2_normalize(r_s, axis=-1)\n",
    "\n",
    "        steps = z_n.shape.as_list()[1]\n",
    "\n",
    "        pos = K.sum(z_s * r_s, axis=-1, keepdims=True)\n",
    "        pos = K.repeat_elements(pos, steps, axis=1)\n",
    "        r_s = K.expand_dims(r_s, axis=-2)\n",
    "        r_s = K.repeat_elements(r_s, steps, axis=1)\n",
    "        neg = K.sum(z_n * r_s, axis=-1)\n",
    "\n",
    "        loss = K.cast(K.sum(K.maximum(0., (1. - pos + neg)), axis=-1, keepdims=True), K.floatx())\n",
    "        return loss\n",
    "\n",
    "    def compute_mask_Layer(self, input_tensor, mask=None):\n",
    "        return None\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0][0], 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import operator\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "num_regex = re.compile(r'^[+-]?[0-9]+\\.?[0-9]*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(token):\n",
    "    return bool(num_regex.match(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(maxlen=0, vocab_size=0):\n",
    "    \n",
    "    source = './' + 'train.txt'\n",
    "\n",
    "    total_words, unique_words = 0, 0\n",
    "    word_freqs = {}\n",
    "    #W_to_Vmodel = gensim.models.Word2Vec.load(\"w2v_embedding\")\n",
    "    fin = codecs.open(source, 'r', 'utf-8')\n",
    "    #input_file=open(source,'r')\n",
    "    #fin=input_file.readlines()\n",
    "    for line in fin:\n",
    "        words = line.split()\n",
    "\t\t#print(words)\n",
    "        #line = line.lower()\n",
    "        #stop_words = ['government','country','state','district','rajya','sabha']\n",
    "        #resultwords  = [word for word in re.split(\"\\W+\",line) if word.lower() not in stop_words]\n",
    "        #line = ' '.join(resultwords)\n",
    "        #is_noun = lambda pos: pos[:2] == 'NN'\n",
    "        #tokenized = nltk.word_tokenize(line)\n",
    "        #nltk.download('averaged_perceptron_tagger')\n",
    "        #words = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)]\n",
    "        #words = str(nouns)\n",
    "        if maxlen > 0 and len(words) > maxlen:\n",
    "            continue\n",
    "\n",
    "        for w in words:\n",
    "            if not is_number(w):\n",
    "                try:\n",
    "                    word_freqs[w] += 1\n",
    "                except KeyError:\n",
    "                    unique_words += 1\n",
    "                    word_freqs[w] = 1\n",
    "                total_words += 1\n",
    "\n",
    "    print(' Reader ::    %i total words, %i unique words' % (total_words, unique_words))\n",
    "    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    vocab = {'<pad>': 0, '<unk>': 1, '<num>': 2}\n",
    "    index = len(vocab)\n",
    "\n",
    "    for word, _ in sorted_word_freqs:\n",
    "        vocab[word] = index\n",
    "        index += 1\n",
    "        if vocab_size > 0 and index > vocab_size + 2:\n",
    "            break\n",
    "    if vocab_size > 0:\n",
    "        print(' Reader ::   keep the top %i words' % vocab_size)\n",
    "\n",
    "    # Write (vocab, frequence) to a txt file\n",
    "#     vocab_file = codecs.open('./vocab', mode='w', encoding='utf8')\n",
    "#     sorted_vocab = sorted(vocab.items(), key=operator.itemgetter(1))\n",
    "#     for word, index in sorted_vocab:\n",
    "#         if word in W_to_Vmodel.wv.vocab:\n",
    "#             if index < 3:\n",
    "#                 vocab_file.write(word + '\\t' + str(0) + '\\n')\n",
    "#                 continue\n",
    "#             vocab_file.write(word + '\\t' + str(word_freqs[word]) + '\\n')\n",
    "#     vocab_file.close()\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_set(phase, vocab, maxlen):\n",
    "    \n",
    "    #assert phase in {'train', 'test'}\n",
    "\n",
    "    source = './' + phase + '.txt'\n",
    "    num_hit, unk_hit, total = 0., 0., 0.\n",
    "    maxlen_x = 0\n",
    "    data_x = []\n",
    "\n",
    "    fin = codecs.open(source, 'r', 'utf-8')\n",
    "    for line in fin:\n",
    "        line=line.lower()\n",
    "        stop_words=['']\n",
    "        words = line.strip().split()\n",
    "        if maxlen > 0 and len(words) > maxlen:\n",
    "            continue\n",
    "        if not len(words):\n",
    "            continue\n",
    "\n",
    "        indices = []\n",
    "        for word in words:\n",
    "            if is_number(word):\n",
    "                indices.append(vocab['<num>'])\n",
    "                num_hit += 1\n",
    "            elif word in vocab:\n",
    "                indices.append(vocab[word])\n",
    "            else:\n",
    "                indices.append(vocab['<unk>'])\n",
    "                unk_hit += 1\n",
    "            total += 1\n",
    "\n",
    "        data_x.append(indices)\n",
    "        if maxlen_x < len(indices):\n",
    "            maxlen_x = len(indices)\n",
    "\n",
    "    print(' Reader ::    <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100 * num_hit / total, 100 * unk_hit / total))\n",
    "    return data_x, maxlen_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(vocab_size=0, maxlen=0):\n",
    "    print(' Reader :: Reading data from training set')\n",
    "    print(' Reader ::  Creating vocab ...')\n",
    "    vocab = build_vocab(maxlen, vocab_size)\n",
    "    print(' Reader ::  Reading dataset ...')\n",
    "    print(' Reader ::   train set')\n",
    "    train_x, train_maxlen = read_set('train', vocab, maxlen)\n",
    "    print(' Reader ::   test set')\n",
    "    test_x, test_maxlen = read_set('test', vocab, maxlen)\n",
    "    maxlen = max(train_maxlen, test_maxlen)\n",
    "    print(train_maxlen)\n",
    "    print(test_maxlen)\n",
    "    return vocab, train_x, test_x, maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
